{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66667ff8",
   "metadata": {},
   "source": [
    "# BMSS 1: Advanced arithmetic\n",
    "\n",
    "\n",
    "## Some basic operators\n",
    "\n",
    "1. **The summation operator, $\\sum$**, tells us to sum from the observation denoted at the bottom of the capital greek letter $\\Sigma$ (\"sigma\", which makes the \"s\" sound, as in **s**um) and go up until the observation denoted on top of the $\\Sigma$. For us, the bottom item will almost always be individual (denoted *i*) equal to one, going up until individual equal to *n*, where *n* is the sample size. Please note carefully that we're using small Latin letters here in two different ways: *i* is an index, which varies across individuals; *n* is a constant and a property of the data-set as a whole. Examine this simple example data-set: \n",
    "\n",
    "    $$\n",
    "    \\begin{array}{|c|c|}\n",
    "        \\hline\n",
    "            \\textbf{i} & \\textbf{y} \\\\\n",
    "        \\hline\n",
    "            \\text{1} & \\text{3} \\\\\n",
    "        \\hline\n",
    "            \\text{2} & \\text{10} \\\\\n",
    "        \\hline\n",
    "            \\text{3} & \\text{2} \\\\\n",
    "        \\hline\n",
    "            \\text{4} & \\text{4.5} \\\\\n",
    "        \\hline\n",
    "    \\end{array}\n",
    "    $$\n",
    "\n",
    "    Now, try to carry out the arithmetic operation indicated by the following notation: $\\sum_{i=1}^n \n",
    "    y_i$.[^answer]\n",
    "    \n",
    "    [^answer]: 3 + 10 + 2 + 4.5 = 19.5\n",
    "\n",
    "    The numbering of individuals is, for our purposes, basically always arbitrary, and summation is \n",
    "    commutative anyways (the order of the items summed, or the *summands*, does not matter), so sometimes you \n",
    "    will see the sub- and superscripts omitted. \n",
    "\n",
    "    Let's suppose that we are interested in someone's highest year of education achieved and we have \n",
    "    observations on *n* = 10 individuals. Let their scores on the education variable be represented by the \n",
    "    vector $\\vec{y} = [10, 12, 16, 12, 18, 10, 20, 18, 9, 10]^T$. All that the little \"T\" represents here is \n",
    "    that this is the transpose of the actual vector, which would be a column in the standard way of \n",
    "    representing data in matrices (rows are individuals, columns are variables). As you can see above, it \n",
    "    wastes a lot of space to represent column vectors the correct way in text documents, so you will see \n",
    "    this convention very often. The idea is that we are making clear that this is a list of different \n",
    "    individuals and *not* the scores for one individual on ten different variables (if we wanted to represent \n",
    "    such a row vector, we'd wouldn't need a $^T$. \n",
    "    \n",
    "    Now, try to sum up these individuals' scores. The order here is arbitrary, but you might as well \n",
    "    conceptualize those scores above as being a specific case of the following \n",
    "    vector: $\\vec{y} = [y_1, y_2, ... y_n]^T$. The last piece of notation is that we we will represent random \n",
    "    variables in their most\n",
    "    abstract form with capital Roman letters; their sample equivalents have lowercase Roman letters. Unlike\n",
    "    in most statistics books, I will consistently use Greek letters without hats to denote true population \n",
    "    parameters (most books usually, but not always, do this) and Greek letters with carets or \"hats\". Greek\n",
    "    letters will be used in the conventional way: the sound they make indicates the parameter. Here, $\\tau$\n",
    "    (\"tau\") stands in for the total. Note that the notation means that to find the sample estimate of the \n",
    "    total of the random variable *Y*, we sum up the observed values in the sample, $y_i$. Note that to \n",
    "    estimate the value of the total, we need to multiply by the probability of selection into the sample. If \n",
    "    each observation has a different probability, we need to put this inside of the summation. In our case, \n",
    "    we'll deal only with the equal probability of selection (*epsem*) method, so this is a constant that can \n",
    "    be factored out. \n",
    "    \n",
    "    \\begin{align*}\n",
    "        \\widehat{\\tau}_Y &= \\pi \\sum_{i=1}^n y_i\n",
    "    \\end{align*}\n",
    "\n",
    "2. **The mean** is a measure of central tendency&mdash;something like the \"characteristic value of a distribution\", which the mean, median and mode all get at. We focus most attention on the mean in this class; however, the median is an important measure, especially in the context of quantiles more generally. **\"Mean\" is simply the formal term for the arithmetic average.** We'll focus on the simple case where possible outcomes are discrete, meaning that they are finite in number or **countably** infinite (more in a second); simple descriptive statistics for any real world data-set can be calculated using these simpler discrete formulae. Sometimes, we will need to discuss variables with infinite possible values, known as continuous variables. \n",
    "\n",
    "    For example, if we record someone's income to the cent, while they could in theory tell us that they have \n",
    "    any number up to infinity, this is *countably* infinite; setting aside the formal definition, this means \n",
    "    basically that if I pick an arbitrary number of functioning cars someone owns (say, five cars), I can tell \n",
    "    you the next value in the set of possible outcomes with no question (six cars); so, cars owned is a \n",
    "    discrete variable. \n",
    "    \n",
    "    By contrast, if we ask someone about their \n",
    "    height and they reply with \"74 inches\", I can't say what height is \"next\". I could, for example, say 75 \n",
    "    inches, but since 74 inches is about 188cm, 189cm is nearer than 75 inches. And this, of course, can \n",
    "    extend even further, to the micron (if we had a microscope). Since height can take on an uncountable \n",
    "    number of possible values: it is continuous. (It is fun, but not super important, to wonder about why some \n",
    "    variables are continuous and others are discrete. In the cars case, it is just definitional; while parts \n",
    "    of cars do exist, if I am only interested in complete, functioning cars, those simply do not come in \n",
    "    halves; by contrast, there is no similar limit on height).\n",
    "    \n",
    "    **The mean is sometimes referred to as the expected value or expectation.** When we write the mean as an \n",
    "    expected value or expectation, we conceptualize it as a population-level property; it is the weighted sum \n",
    "    of all possible values of the variable. So, we are summing over the possible outcomes of the variable when \n",
    "    we write the mean as an expectation&mdash;we are **not** summing over any observed individuals. \n",
    "    Many textbooks and internet sources do not change their notation here, which confuses new students, so I \n",
    "    will now re-index the sum. Let *k* index an outcome of the random variable *Y* (i.e., \"*k*=5\" would mean \n",
    "    the fifth possible outcome, where order again typically does not matter) and let *K* indicate the number \n",
    "    of possible outcomes. Then, for a *discrete* random variable (don't worry about the continuous formlua \n",
    "    here):  \n",
    "    \n",
    "    \\begin{align*}\n",
    "    \\mathbb{E}[Y] &= \\sum_{k=1}^K y_k * \\mathbb{P}(Y=y_k)\n",
    "    \\end{align*}\n",
    "\n",
    "    This says that we look at each possible outcome *k*, starting with *k* = 1, and multiple the value of that \n",
    "    outcome $y_k$ by its probability of occurring, $\\mathbb{P}(Y=y_k)$. \n",
    "    \n",
    "    For a given *set* of data, the formula does not change, even if the variable is itself continuous; this is \n",
    "    because all actual observed data-sets are discrete: there is a finite number of observed values. If we \n",
    "    have any repeated values, we effectively use this as a sample estimate of the probability of observing \n",
    "    that value at  the population level. If the variable itself has many possible outcomes (whether it is \n",
    "    discrete or continuous) and no values repeat themselves exactly, then the estimated probability of each \n",
    "    value is just $\\frac{1}{n}$. \n",
    "\n",
    "    So, in practice, with equal probability sampling, it is often simpler to write out the mean as the simple \n",
    "    arithmetic mean, even if we have repeat values. \n",
    "   \n",
    "    Note one exception for our notation rules mentioned above: It would make *most* sense to use, for the \n",
    "    sample mean, the notation $\\widehat{\\mu}_Y$. However, most textbooks use the notation $\\bar{Y}$ for the \n",
    "    random variable and $\\bar{y}$ for some specific sample mean. The problem with this notation is that it \n",
    "    breaks the general rule about Greek and Roman letters mentioned above and requires you to  memorize a new \n",
    "    notational rule, but it is extremely common, so we will use it. For any specific sample mean...\n",
    "    \n",
    "    \\begin{align*}\n",
    "    \\bar{y} &= \\sum_{i=1}^n \\frac{1}{n} * y_i \\cr\n",
    "    \\bar{y} &=  \\frac{1}{n} \\sum_{i=1}^n* y_i  \\\n",
    "        &&  \\text{since $\\frac{1}{n}$ is constant, it factors out of the sum} \\cr\n",
    "    \\end{align*}\n",
    "    \n",
    "    Note that this means that a *simple* mean implicitly takes the inclusion of each member of the sample to \n",
    "    have been equally probable. This is false with a stratified random sample. So, we fix this by multiplying \n",
    "    by the inverse of the probability of inclusion, the *sample weight* $w = \\frac{1}{\\pi_i}$, where $\\pi_i$ \n",
    "    is *i*'s probability of being included in the sample as $\\pi_i$. Note that $\\pi_i$ is a parameter, not a \n",
    "    statistic; every member of our sample has a *known* probability of inclusion. \n",
    "    In the case of simple random sampling, every member of the population has an equal probability of \n",
    "    inclusion of $\\frac{n}{N}$, where *n* is the sample size and *N* is the population size. \n",
    "    \n",
    "    \\begin{align*}\n",
    "     \\bar{y} &= \\frac{1}{N} \\sum_{i=1}^n \\frac{1}{\\pi_i} * y_i \\cr\n",
    "    &= \\frac{1}{N} \\sum_{i=1}^n \\frac{N}{n} * y_i && \\text{note that $\\pi_i$ = $\\frac{n}{N}$} \\cr\n",
    "    &= \\frac{1}{N} * \\frac{N}{n} \\sum_{i=1}^n y_i && \\text{constants factor out of sums} \\cr\n",
    "    &= \\frac{1}{n}\\sum_{i=1}^n y_i\n",
    "    \\end{align*}\n",
    "    \n",
    "    Note that this formula is helpful because is can be extended to cases where we don't have equal \n",
    "    probabilities of inclusion. \n",
    "    \n",
    "    For some practice, try calculating the sample mean for the data-set given above.[^answer3]\n",
    "    \n",
    "    [^answer3]: (3 + 10 + 2 + 4.5)/4 = 4.875\n",
    "\n",
    "3. **The variance** is a measure of spread or dispersion. You can think about it as the expected difference between a randomly-selected observation and its mean. We define it formally at the population-level as the expectation of the difference between the random variable *Y* and its mean $\\mu_Y: \\mathbb{V}[Y] = \\mathbb{E}[(Y - \\mu)^2]$. You may wonder why we square the difference. There is a very good reason for this that leads us to the proof of a useful fact about the mean, which is that it is the value for a given set about which all deviations are not just minimized but also zero!\n",
    "\n",
    "    \\begin{align*}\n",
    "    &1. \\mathbb{E}[Y - \\mu_Y] = \\mathbb{E}[Y] - \\mathbb{E}[\\mu_Y] \n",
    "                && \\text{expectation operator is linear} \\cr\n",
    "    &2. \\mathbb{E}[Y] = \\mu_Y && \\text{by definition} \\cr\n",
    "    &3. \\mathbb{E}[\\mu_Y] = \\mu_Y && \\text{expectation of a constant is just that constant} \\cr\n",
    "    &4. \\mathbb{E}[Y - \\mu_Y] = \\mu_Y - \\mu_Y = 0  && \\text{arithmetic}\n",
    "        \\end{align*}   \n",
    "        \n",
    "    It is useful to think about the variance operator, $\\mathbb{V}$ as a function that produces the variance, and the actual variance itself as a fixed quantity for a given population. We will denote this $\\sigma^2$. Do not let yourself get frustrated by the power of 2. The reason we do this is quite simple: the variance is easier to *calculate* with, but the interpretation&mdash;the expected squared distance of a point from the mean, or the average squared distance of a point from the mean&mdash;is more difficult. One solution is to just take the root of the whole thing, which we then call the standard deviation, which is $\\sigma$ for the population and *s* in the sample (the sample variance is then *s*^2). \n",
    "    \n",
    "    The sample variance formula is also straightforward, with the exception of the denominator. Don't worry too much about this; it is called the Bessel correction, and it fixes the bias caused by the fact that we estimate the population mean with the sample mean, which understands the true variance (the spread of the points will generally be closer to the sample mean than the population mean). But, the variance is still fundamentally the mean squared deviation. \n",
    "    \n",
    "    \\begin{align*}\n",
    "        s^2 = \\frac{\\sum_{i=1}^n (y_i - \\bar{y})^2}{n-1} \\cr\n",
    "        s = \\sqrt{\\frac{\\sum_{i=1}^n (y_i - \\bar{y})^2}{n-1}}\n",
    "    \\end{align*}\n",
    "\n",
    "    Finally, try to calculate the sample variance of our data-set above. [^answer4]\n",
    "    \n",
    "    [^answer4]: Individual 1's squared deviation is (3-4.875)^2 = 3.52. Individual 2's squared deviation is \n",
    "    (10-4.875)^2 = 26.27. Individual 3's squared deviation is (2-4.875)^2 = 8.27. Individual 4's squared \n",
    "    deviation is (4.5-4.875)^2 = 0.14. The total sum of squares (TSS) is 38.2; the (near) mean is 38.2/3 = \n",
    "    12.73 and the root thereof is 3.57. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55aa806",
   "metadata": {},
   "source": [
    "# Distributions: regular variable and sampling\n",
    "\n",
    "## Discrete distributions: cumulative distribution and probability mass functions \n",
    "\n",
    "We saw above some methods of characterizing distributions by their parameters (their mean and standard deviation), but what if we want to examine the distribution overall? We need to look at this separately for discrete and continuous variables. We'll start with what I'm calling *regular variable* distributions, distributions that characterize an actual variable of interest, such as mother's education or income or age; then, we'll turn to *sampling* distributions, distributions that characterize the behavior of a sample statistic over many different samples. This second quantity is of interest to us for *inferential reasons*; we care about income, but to make inference about income, we need to understand the behavior of sample means of income across many samples. This difference is *extremely* important, and in many years of teaching this material, I have found that the most common mistake students make is to ignore this distinction or to realize that one does not understand it but to be excessively easygoing about this fact. You *must* make sure that you understand this difference. \n",
    "\n",
    "There are two useful ways to examine an individual distribution for discrete variables. The first is a cumulative distribution function (CDF), which plots on the X-axis the value of the variable and on the Y-axis, the cumulative percent (i.e., probability) of data observed up to that value. A CDF makes sense for both continuous and discrete random variables. The height of this function is the percent of observations less than or equal to some value of the variable; remembering that percent and probabilities usually are the same thing, and letting $\\mathbb{P}$ mean \"probability\", the height of this function $F(X) = \\mathbb{P}(X \\leq x)$. \n",
    "\n",
    "The second is a probability mass function (PMF), which plots possible values of the variable on the X-axis (again), but this time plots the probability of observations *just for that value* on the Y-axis. You can see these two approaches belows. Notice that a PMF is basically just a histogram. The height of this function is the percent of observations *exactly* equal to some value of the variable; the height of this function $F(X) = \\mathbb{P}(X = x)$. \n",
    "\n",
    "![CDF and PMF](./figures/pmfcdfnumkids.png)\n",
    "\n",
    "## Continuous distributions: probability density functions \n",
    "\n",
    "For continuous variables, we can also generate cumulative distribution functions, but probability mass functions don't, strictly speaking, make sense. This is because the probability of any exact value of such a variable is zero. This is surprising at first, but if you have trouble buying this, imagine the probability of any specific value of a variable which could possibly be equal to, say, $\\pi$ or *e* (i.e., irrational numbers)&mdash;if it's not zero, it's extremely small, right? \n",
    "\n",
    "It is important to note that *all* actual, observed populations are, practically speaking, \"discrete\" in that the number of outcomes is finite. So, while a variable can have a PDF, any dataset of *realizations* cannot; we just have an estimate of the PDF, which is actually a PMF. For example, here is the empirical CDF and PMF of height from the 2017-18 NHANES. Height is a continuous variable, but the realization of it in this sample is discrete, even if it is massively less-discrete than the number of children seen above. If you look carefully, you can see the slight \"kinks\" in the line; these are not problems of pixellation but rather that this is an empirical estimate of continuous function. \n",
    "\n",
    "![CDF and PMF for realization of continuous variable](./figures/height_CDF_P'D'F.png)\n",
    "\n",
    "What do actual density functions look like and represent, then? Cumulative distribution functions look nearly the same, and the function F(X) means the same thing: the probability that the variable takes on value less than or equal to some value X; formally $\\mathbb{P}(X \\leq x)$. *Density* is a trickier concept; what it means formally is *probability per unit*. You should think about density as the \"speed of probability\"; the PDF is just a graph of the *speed* of the CDF (formally, the PDF is the simple first derivative of the CDF). So, note that the graph of the PDF is *tallest* where the slope of the CDF is *steepest*. \n",
    "\n",
    "Importantly, this means that the *height* of the PDF is not of direct interest, both because the height is hard to interpret intuitively, even if the mathematical definition is simple; and, at any rate, . What we care about instead are *areas under the curve* between two points *a* and *b*, which *are* probabilities (not densities) that the variable will take on a value between *a* and *b*.[^fn_auc]\n",
    "\n",
    "[^fn_auc]: Formally, where $f(X)$ is the generic notation for a PDF, $\\int_a^b f(X) = \\mathbb{P}(a \\leq X \\leq b)$.\n",
    "\n",
    "So, what are PDFs good for? Well, we can use them to model the probability distribution of a random variable. Remarkably, it turns out that the random variable $\\overline{Y}$ is 1) continuous and 2) Normally-distributed, even if the distribution of the random variable *Y* is far from Normally-distributed&mdash;this is the power of the Central Limit Theorem. Here is a simulation we've seen before in this class, using a large number of replications (so, this is not the true PDF, but it gives us a clear sense of what that would look like). Further, we happen to know its \n",
    "\n",
    "![The power of the central limit theorem](./figures/CLT_power.png)\n",
    "\n",
    "Here are the Standard Normal CDF and PDF, which characterize the distribution of standardized sample means. All sample means are Normally-distributed, but they have arbitrary means and standard deviations; subtracting the mean and dividing by the standard deviation gives a standard score $z = \\frac{\\overline{y} - \\mu_{\\overline{Y}}}{\\sigma_{\\overline{Y}}}$. We typically won't actually know the mean and standard deviation, but I'll address that in a little bit. \n",
    "\n",
    "![Standard Normal CDF and PDF](./figures/Normal_CDF_PDF.png)\n",
    "\n",
    "Now, it is worth noting that although it is difficult to take the areas under the curve (AUC) of the Normal by hand with calculus, it is easy to do so with a computer or a table. Further, the AUCs associated with +/- one, two, and three standard deviations are easy to memorize. In particular, the fact that going out exactly 1.96 standard deviations includes almost exactly 95 percent AUC is very easy to remember, and if you've heard of a 95 percent confidence interval (which is extremely standard, though technically arbitrary), this is why.\n",
    "\n",
    "![Areas under the curve of the NormalPDF](./figures/Normal_PDF_AUCs.png)\n",
    "\n",
    "If the population is sufficiently large relative to the the size of the sample, each individual observation can be treated as independent of the others and taken from the same distribution (so long as they are drawn at random): they are \"independent, identically-distributed\" (IID) random variables.\n",
    "\n",
    "This concept is often very challenging for novices, so I want you to go back and re-read the preceding paragraph. *Each person in our sample, before they are actually selected, is a random variable*. For example, if I plan to sample 500 people and ask them their income, but I have not yet done so, those 500 hypothetical-people represent 500 random variables, all taken from the same population distribution of income. It is often helpful to consider the analogy to an experiment in which we flip coins: the concept of \"the outcome of the 10th coin I flip\" is more-obviously a random variable for the simple reason that it hasn't yet happened. While the person whose income I ultimately observe in the sample has already *obtained* that income, there is a point at which I don't know *which* person I'll observe, and thus that \"person's\" income is rather like the outcome of the as-yet-unflipped coin. \n",
    "\n",
    "Here is the extremely important fact about that. When we do inference about a population, we cannot observe it, and we do not know its distribution; its distribution likely does not fit some exact mathematical function anyways (and it may not be well-approximated by one). So, observing the realization of *one* random variable&mdash;taking one person out of the population and asking, say, their income&mdash;is not very informative. When we turn a set of random variables into a total or a mean, however, we know that the shape of the distribution *they* come from is not the (unknown) \"regular variable\" distribution but the sampling distribution. *This is the primary reason why (pre-super computer) statistics is even possible*. It is such a striking fact that Galton claimed that \"[[t]he law would have been personified by the Greeks and deified, if they had known of it](https://galton.org/cgi-bin/searchImages/galton/search/books/natural-inheritance/pages/natural-inheritance_0073.htm)\". \n",
    "\n",
    "## Basics of inference\n",
    "\n",
    "So, we can now do inference! All we need to do is find the standard score of a sample mean and then find the associated AUC. Recall before that sample means are unbiased estimators for simple random samples, so our mean of the sampling distribution, $\\mu_{\\overline{Y}}$, is simply the population mean, $\\mu_Y$. \n",
    "\n",
    "Now, we are after the standard deviation of the sample mean, which is referred to as the standard error for the sake of distinguishing it from the \"regular variable\" standard deviation. It turns out that it is much easier to derive the variance and then simply take the root. Note that we are after the variance of a sum of IID random variables (divided by the constant *n*).  While the extremely useful general formula for the variance of a sum of random variables is slightly complex (see appendix), it is not just extremely useful but extremely simple for independent random variables: it is just the sum of their variances. Let $\\overline{Y}$ represent the sample mean of a random variable comprised of *n* IID random variables $Y_1, Y_2, ... Y_n$; each variable comes from a population distribution with standard deviation $\\sigma_Y$, which we'll simply refer to using $\\sigma$ for simplicity.  \n",
    "\n",
    "   \\begin{align*}\n",
    "    \\mathbb{V}[\\overline{Y}] = \\sigma^2_{\\overline{Y}} &= \\sum_{i=1}^n \\mathbb{V}[\\frac{Y_i}{n}] \\cr\n",
    "    &= \\sum_{i=1}^n \\frac{1}{n^2} \\mathbb{V}[Y_i] \\cr\n",
    "    &= \\frac{1}{n^2} (\\sigma^2_1 + \\sigma^2_2 + ... + \\sigma^2_n) \\cr\n",
    "    &= \\frac{1}{n^2} n*\\sigma^2 \\cr\n",
    "    &= \\frac{\\sigma^2}{n} \\cr\n",
    "    \\sigma_{\\overline{Y}} &= \\frac{\\sigma}{\\sqrt{n}}\n",
    "    \\end{align*}\n",
    "\n",
    "Finally, here comes our last step. Note that we are planning to do inference on the mean, but we do not know it! How can we use our formula? Well, we can do one of two things. \n",
    "\n",
    "First, we can simply recognize that, for example, about 68 percent of sample means will fall within +/- two standard deviations of the true population mean. So, we can simply add and subtract one standard error to our sample mean to have a 68 percent chance of having that mean $\\mu_Y$ in there. It's more conventional to use a higher level of \"confidence\" and add and subtract 1.96 standard errors to our sample mean to have a 95 percent chance of including $\\mu_Y$. The general formula for a confidence interval with confidence level *C* is $CI_{C} = \\overline{y} +/- z_C*\\frac{\\sigma}{\\sqrt{n}}$, where $z_C$ is the number of standard deviations within which *C* percent of the AUC lie. For the sake of our class, just use $z_{95} = 1.96$. \n",
    "\n",
    "Below is a picture of why this works. Suppose that we have population level data on mother's education. Below is what the sampling distribution would look like, with five sample means plotted and their \"error bars\" attached. Notice that, although no sample mean is identical, all five happen[^fn_bin] to include the true population mean. In the long run, we should expect this procedure to work 95 percent of the time. \n",
    "\n",
    "[^fn_bin]: Incidentally, the probability of five randomly drawn sample means, each with $\\mathbb{P}$(CI contains $\\mu_Y$) = 0.95, all including $\\mu_Y$ is, from the binomial distribution, $\\binom{5}{5}*0.95^5*0.5^{5-5} = 1 * 0.95^5 * 1 = 0.77$, or about 77 percent.\n",
    "\n",
    "![The logic of a confidence interval](./figures/z_CI_demo.png)\n",
    "\n",
    "Our second technique is a statistical *test*. This works for fundamentally the same reason as a confidence interval, and they are functionally the same for means (for other kinds of statistics, there will be more reason to prefer the CI or the test). We picture the sampling distribution under a null hypothesis ($H_0$) that the true mean is equal to some value $\\mu_0$, and then we calculate the standard score if that were true and finally find the associated probability. If that $\\mathbb{P}$-value is small (say, less than 0.05), we reject the null hypothesis. The level at which we reject the null, known as $\\alpha$, is arbitrary. \n",
    "\n",
    "It is conventional to take the $\\mathbb{P}$-value not just of the statistic we actually get, but also its additive inverse. This is shown below. \n",
    "\n",
    "![The logic of a statistical test](./figures/ztest_demo.png)\n",
    "\n",
    "Finally, there is just one more complication to be aware of. In practice, we do not know $\\sigma$, so we estimate it with *s*. This causes additional uncertainty in our estimate, and it is now taken from a distribution that is close to Normal but is farther from Normal the smaller the sample size. Many statistical textbooks get very excited about this; I think that this is, for the non-mathematician, a boring technical detail. I will simply say that this means that your should look up your test statistic in a *t*-table, not a *z*-table, but the basic meaning of a CI or $\\mathbb{P}$-value is the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff88657",
   "metadata": {},
   "source": [
    "# Bivariate analysis: tests for a difference in means\n",
    "\n",
    "Suppose that we are interested in determining whether two groups differ on some key outcome variable, such as their level of education or income. Let's be clear and formalistic about what we are after: we want to know whether or not, say, $\\mu_{income | white}  = \\mu_{income | black}$ or $\\mu_{education | male}  = \\mu_{education | female}$, where, to avoid the confusion caused by double subscripts, I've used the standard notation of a vertical bar to indicate \"given that one is...\". \n",
    "\n",
    "An obvious move here is just to replace these with their sample equivalents. So, using the older (if more confusing) notation for a sample mean, we might check whether $\\overline{educ}_{male} = \\overline{educ}_{female}$. And, in fact, this is exactly the right idea. The question now, however, is whether or not this difference is liable to have arisen by chance. \n",
    "\n",
    "You should stop and really consider this for a moment because this is the entire idea behind *inferential* statistics, as opposed to simply descriptive statistics (recall: descriptive statistics are just ways of summarizing the data we have, whether these are population-level or sample-level, without reference to whether these represent some other group). Why can't I trust, say, an observed difference of a year between a group of men and women? \n",
    "\n",
    "One intuitive reason not to trust this, and this is what you'll almost always hear in internet arguments about this sort of thing from people who are a little learnèd (if not too learnèd), is that the sample size might be too small. It turns out that this is a little too conservative: we need to *adjust* for small sample sizes, but if we have a truly random sample, any data are better than no data, and we can just adjust for the small sample size. \n",
    "\n",
    "Another reason not to trust this is that we don't have access to the whole population. This is really just the same objection as above: the sample size is too small. But, there's a subtle difference here: in this case, the gripe cuts to the heart of the matter. We don't just have a \"small\" sample size, whatever that might mean. We have a *sample*, period: some group of people smaller than the population we care about. And samples are noisy processes; that's what makes them great, in fact&mdash;they differ from the population only by random error (\"noise\"). But, we do need to take account of the error. So, how do we do that? \n",
    "\n",
    "Let's actually start with an easier, if slightly less-interesting, question: how would we do this for just one group's mean? It turns out that to calculate the sampling noise, we need a little bit of theory. \n",
    "\n",
    "### The Central Limit Theorem (CLT)\n",
    "\n",
    "To make a judgment call about whether or not a sample mean $\\overline{Y}$ represents a population mean $\\mu_Y$, we need to have some sense for how the sample mean behaves across many samples. In other words, we need to know the probability distribution (technically: the probability density function, or PDF) of sample means. \n",
    "\n",
    "#### Histograms and probability distributions\n",
    "\n",
    "I will presume here that you are at least loosely familiar generally with histograms, from which we'll build an intuition for the Normal PDF; in the class for which these notes are being prepared, I'll have slides that walk you through how those work. Histograms are basically sample approximations of PDFs. On the X-axis, we have the possible-outcomes[^fn] for a variable; on the Y-axis, we have some kind of indication of the frequency of observations. So, any individual bar tells us the frequency of observations taking on a certain possible-value. For example, in the histogram for education below, about five percent of observations took on the value 11, meaning that five percent of the sample had 11 years of education. \n",
    "\n",
    "[^fn]: There is, unfortunately, no single-word term for \"possible outcomes\", which is a strange oversight. \n",
    "\n",
    "![Simple histogram for education](./figures/hist_educ.png)\n",
    "\n",
    "PDFs are just the equivalent of a histogram when 1) we know about the true population distribution and 2) we have a continuous random variable. Recall that all actual sample data are discrete: we stop measuring the digits at a certain point (e.g., we measure height only to the tenth of an inch in some data-sets). But, in principle, height could be measured infinitely more-precisely with better and better microscopes, so it is a continuous random variable. But, it is rare to really know the PDF of a real-world variable; height happens to be approximately Normal, which is why I picked it as an example, but this is still only an approximation. \n",
    "\n",
    "![Simple histogram for height](./figures/hist_height.png)\n",
    "\n",
    "However, it turns out, quite impressively, that sample means are Normally-distributed across many samples: this is the Central Limit Theorem (CLT). In other words, if you had a population from which you could take an infinite number of samples (with replacement), the histogram of sample means would basically be indistinguishable from a smooth, Normal curve. We'll learn two useful techniques that use this fact in due time.  \n",
    "\n",
    "If the population is sufficiently large relative to the the size of the sample, each individual observation can be treated as independent of the others and taken from the same distribution (so long as they are drawn at random): they are \"independent, identically-distributed\" (IID) random variables.\n",
    "\n",
    "It is important to note that each observation of the sample, before they are actually observed, is a random variable: when some researcher plans to sample 500 people and ask them their income, and she has not actually selected any individuals for inclusion, the income of the *i*th person, $Y_i$ is still a random variable. So, when we talk abstractly about the variance of a sample mean across many samples, we need to treat these sample means themselves as random variables. This is a major source of confusion early on, so remain *en garde* here: each actual observation in the sample is the *realization* of a random variable. It is often helpful to consider the analogy to an experiment in which we flip coins: the concept of \"the outcome of the 10th coin I flip\" is more-obviously a random variable for the simple reason that it hasn't yet happened. While the person whose income I ultimately observe in the sample has already *obtained* that income, there is a point at which I don't know *which* person I'll observe, and thus that \"person's\" income is rather like the outcome of the as-yet-unflipped coin. \n",
    "\n",
    "So, we are after the variance of a sum of IID random variables (divided by the constant *n*).  While the extremely useful general formula for the variance of a sum of random variables is slightly complex (see appendix), it is not just extremely useful but extremely simple for independent random variables: it is just the sum of their variances. Let $\\overline{Y}$ represent the sample mean of a random variable comprised of *n* IID random variables $Y_1, Y_2, ... Y_n$; each variable comes from a population distribution with standard deviation $\\sigma_Y$, which we'll simply refer to using $\\sigma$ for simplicity.  \n",
    "\n",
    "   \\begin{align*}\n",
    "    \\mathbb{V}[\\overline{Y}] = \\sigma^2_{\\overline{Y}} &= \\sum_{i=1}^n \\mathbb{V}[\\frac{Y_i}{n}] \\cr\n",
    "    &= \\sum_{i=1}^n \\frac{1}{n^2} \\mathbb{V}[Y_i] \\cr\n",
    "    &= \\frac{1}{n^2} (\\sigma^2_1 + \\sigma^2_2 + ... + \\sigma^2_n) \\cr\n",
    "    &= \\frac{1}{n^2} n*\\sigma^2 \\cr\n",
    "    &= \\frac{\\sigma^2}{n} \\cr\n",
    "    \\sigma_{\\overline{Y}} &= \\frac{\\sigma}{\\sqrt{n}}\n",
    "    \\end{align*}\n",
    "    \n",
    "#### The standard error (sampling noise) for a difference in means\n",
    "\n",
    "It turns out that the difference in means, which we tend to conceive naturally as two things combined, can be thought of as simply the mean of a single \"difference\" variable. This variable turns out to have a slightly different *t* distribution, and the exact calculation of degrees of freedom becomes somewhat involved (in fact, degrees of freedom no longer have to be integers, which is quite an interesting fact), but these are details that aren't really essential to an understanding of the basic point: we have a nearly-Normal sampling distribution for this difference in means.\n",
    "\n",
    "Fortunately, we have also already learned the key rule for the standard error for a difference in means; if two random variables are independent, the variance of the variables' sum *or* difference is just the sum of the variances. So, the sampling variance here is simply $\\sigma^2_{\\overline{Y}_F} + \\sigma^2_{\\overline{Y}_M}$, and the standard error is the root thereof. \n",
    "\n",
    "So, we can simply standardize the difference between two sample means \n",
    "\n",
    "## Using the distribution of sample statistics across many samples: tests and confidence intervals\n",
    "\n",
    "As noted above, one of the most important theorems in statistics is the Central Limit Theorem (CLT), which states that the distribution of many important sample statistics, such as the mean or the difference in means (and many more), has an approximately Normal distribution; there are many related theorems that give the distribution for other sample statistics (such as the variance, which has what is called the $\\chi^2$ distribution). \n",
    "\n",
    "There are two very useful things that we can do with this information. They basically come to the same thing, but there are settings where one or the other is more natural. These two things are known as *confidence intervals* and *hypothesis tests*. \n",
    "\n",
    "A confidence interval exploits the fact that we know how many standard deviations we need to go above and below the mean $\\mu$ of a sampling distribution to capture some central area, which you should recall is also a probability (this is tough to calculate by hand, but since people have long recognized how useful it would be, we have standard tables where we can look these things up; it is also available as a function on basically all computer software). If we then simply add and subtract the margin of error&mdash;the number of standard deviation we need times the size of the standard deviation for some specific sampling distribution&mdash;we can get a range that has a given probability of including the true parameter. We pick the probability (known as the \"level of confidence\") based on convention or some exogenously-determined need for precision; there is no mathematically \"correct\" level. Then, we find the number of standard deviations needed. For the sake of this class, just use the ultra-conventional 95 percent level of confidence.\n",
    "\n",
    "For example, a common usage of a confidence interval is as follows: \n",
    "\n",
    "1. We know that 95 percent of sample means fall within about +/- 1.96 standard deviations of the true mean. \n",
    "2. We know that the standard deviation of a sampling distribution is given by $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "3. Technically, we almost always have to estimate that standard deviation with $\\frac{s}{\\sqrt{n}}$, causing calculations involving it to be *t*-distributed. This, in most cases, won't significantly change the number of standard deviations that we need to use, but it may. In either case, look these up. \n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095a821",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "### An extremely useful alternative expression for the variance.\n",
    "\n",
    "\\begin{align*}\n",
    "            &1. \\mathbb{V}[Y] = \\mathbb{E}[(Y - \\mu_Y)^2] && \\text{definition} \\cr\n",
    "            &2. = \\mathbb{E}[Y^2 - 2*\\mu_Y*Y + \\mu_Y^2] && \\text{binomial expansion AKA \"FOILing\"} \\cr\n",
    "            &3. = \\mathbb{E}[Y^2] - \\mathbb{E}[2*\\mu_Y*Y] + \\mathbb{E}[\\mu_Y^2] \n",
    "                && \\text{expectation operator is linear} \\cr\n",
    "            &4. = \\mathbb{E}[Y^2] - 2*\\mu_Y*\\mathbb{E}[Y] + \\mathbb{E}[\\mu_Y^2]\n",
    "                && \\text{constants can be factored out} \\cr\n",
    "            &5. = \\mathbb{E}[Y^2] - 2*\\mu_Y*\\mu_Y + \\mathbb{E}[\\mu_Y^2]\n",
    "                && \\text{definition of expectation} \\cr\n",
    "            &6. = \\mathbb{E}[Y^2] - 2*\\mu_Y^2 + \\mu_Y^2\n",
    "                && \\text{expectation of a constant is just that constant, definition of square} \\cr\n",
    "            &7. = \\mathbb{E}[Y^2] - \\mu_Y^2\n",
    "                && \\text{arithmetic} \\cr\n",
    "            &8. \\mathbb{V}[Y] = \\mathbb{E}[Y^2] - \\mathbb{E}[Y]^2\n",
    "                && \\text{definition of expectation} \\cr\n",
    "\\end{align*}\n",
    "        \n",
    "In the sample, this becomes...\n",
    "\n",
    "\\begin{align*}\n",
    "            &1. s^2 = \\frac{\\sum_{i=1}^n (y_i - \\bar{y})^2}{n-1} && \\text{definition} \\cr  \n",
    "            &2. = \\frac{\\sum_{i=1}^n (y_i^2 - 2y_i\\bar{y} + \\bar{y}^2)}{n-1} \\\n",
    "                && \\text{binomial expansion AKA \"FOILing\"} \\cr\n",
    "            &3. = \\frac{\\sum_{i=1}^n y_i^2 - \\sum_{i=1}^n 2y_i\\bar{y} + \\sum_{i=1}^n \\bar{y}^2}{n-1} \n",
    "                && \\text{summation operator is linear} \\cr\n",
    "            &4. = \\frac{\\sum_{i=1}^n y_i^2 - 2\\bar{y}\\sum_{i=1}^n y_i + n\\bar{y}^2}{n-1} \n",
    "                && \\text{constants can be factored out} \\cr\n",
    "            &5. = \\frac{\\sum_{i=1}^n y_i^2 - 2\\bar{y}n\\bar{y} + n\\bar{y}^2}{n-1} \n",
    "                && \\text{definition of summation} \\cr\n",
    "            &6. = \\frac{\\sum_{i=1}^n y_i^2 - n\\bar{y}^2}{n-1} \n",
    "                && \\text{arithmetic} \\cr\n",
    "            &7. = \\frac{n}{n-1} (\\overline{y^2} - \\bar{y})^2\n",
    "                && \\text{arithmetic} \\cr\n",
    "\\end{align*}\n",
    "\n",
    "### The general formula for the variance of a sum of random variables. \n",
    "\n",
    "Let *Y* be the sum of random variables $Y_1, Y_2, ... Y_k$. Assume centered variables for the sake of step 5, where we will want to replace each variable's deviation from its mean with a single symbol to make the multinomial expansion easier. This can be, in principle, any symbol; it seems most natural to just use the variable itself, and we often assume centered variables anyways. Note that there is absolutely no difference if I had used, say, $\\Delta_{Y_j}$ to represent the deviation of the *j*th variable from its mean. \n",
    "\n",
    "To get an intuition for the correct algorithm for multinomial expansion, draw a picture of rectangle with both unique side lengths partitioned into $Y_1, Y_2, ... Y_k$. Then, find the area of the rectangle, which is logically equal, of course, to finding $(Y_1 + Y_2 + ... Y_k)^2$. The rectangle is now comprised of smaller rectangles with areas $(Y_1*Y_1), (Y_2*Y_1) ... (Y_k*Y_1)$ going down the first column, $(Y_1*Y_2), (Y_2*Y_2) ... (Y_k*Y_2)$ going down the second, etc. We can thus visualize this as operation as follows: write out $(Y_1 + Y_2 + ... Y_k)^2$ as $(Y_1 + Y_2 + ... Y_k)*(Y_1 + Y_2 + ... Y_k)$. Starting with the first (or second; it doesn't matter) set of parentheses, take each term, multiply it by every term in the second set of parentheses, then add them up, and then do this for each term in the first set. Then, add up all the summed terms. This corresponds to summing up all of the items in the variance-covariance matrix. It was too time-consuming for me to draw a picture of all of this in Markdown, but DeVellis (2003) is a good, unintimidating visual representation of this sort of proof (which is really useful in general in the context of statistics). \n",
    "\n",
    "By the way, it may be useful to note that to sum all entries in a matrix, we can write it as a quadratic form. If we have centered variables, our covariance matrix $\\boldsymbol{\\Sigma}$ is simply $\\frac{1}{n-1}\\textbf{X}^t\\textbf{X}$, where $\\textbf{X}$ is the data matrix. Then, to sum all elements in that matrix, we write. $\\vec{1}^t\\boldsymbol{\\Sigma}\\vec{1}$. This proof won't use matrix properties, though. \n",
    "\n",
    " \\begin{align*}\n",
    "            &1. \\mathbb{V}[Y] = \\mathbb{E}[(Y - \\mu_Y)^2] && \\text{definition of variance} \\cr\n",
    "            &2. = \\mathbb{E}[([Y_1 + Y_2 + ... Y_k] - \\mu_Y)^2] && \\text{definition of variable Y} \\cr\n",
    "            &3. = \\mathbb{E}[([Y_1 + Y_2 + ... Y_k] - [\\mu_{Y_1} + \\mu_{Y_2} + ... \\mu_{Y_k}])^2] \\\n",
    "                && \\text{expectation operator is linear} \\cr\n",
    "            &4. = \\mathbb{E}[(Y_1 - \\mu_{Y_1} + Y_2 - \\mu_{Y_2} + ... Y_k - \\mu_{Y_k})^2]\n",
    "                && \\text{commutativity of addition} \\cr\n",
    "            &5. = \\mathbb{E}[(Y_1 + Y_2 + ... Y_k)^2]\n",
    "                && \\text{definition of centered variables} \\cr\n",
    "            &6. = \\mathbb{E}[Y_1^2 + (Y_2 * Y_1) + ... (Y_k * Y_1) + (Y_1 * Y_2) + Y_2^2 + (Y_3 * Y_2) ... ]\n",
    "                && \\text{picture the rectangle as mentioned above} \\cr\n",
    "            &7. = \\mathbb{E}[\\sum_{j=1}^k\\sum_{i=1}^k Y_i * Y_j]\n",
    "                && \\text{generalizing the pattern} \\cr\n",
    "            &8. = \\sum_{j=1}^k\\sum_{i=1}^k \\sigma^2_{Y_i, Y_j}\n",
    "                && \\text{definition of(co)variances} \\cr\n",
    "            &9. = \\sum_{j=1}^k \\sigma^2_{Y_j} + 2\\sum_{i>j}^k\\sum_{j=1}^k \\sigma^2_{Y_i, Y_j}\n",
    "                && \\text{covariance matrix is symmetric}\n",
    "        \\end{align*}\n",
    "\n",
    "Of course, we often work with variables&mdash;such as the sample means of women's education and that of men, $\\overline{Y}_F$ and $\\overline{Y}_{M}$&mdash;whose population covariance $\\sigma_{\\overline{Y}_F, \\overline{Y}_M}$ is equal to zero. Then, only the first term of line 9 above is relevant to the calculation of the variance of a random variable which is itself the summation or addition of other random variables. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
